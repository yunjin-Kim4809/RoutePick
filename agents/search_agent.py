import json
import asyncio
import os
import random 
from typing import Any, Dict, Optional, List
from openai import AsyncOpenAI
import googlemaps
from .base_agent import BaseAgent
from tools.tavily_search_tool import TavilySearchTool

class SearchAgent(BaseAgent):
    """
    ì‚¬ìš©ìì˜ í…Œë§ˆë¥¼ [í–‰ë™ ë‹¨ìœ„]ë¡œ ë¶„ì„í•˜ì—¬ [ì½”ìŠ¤ êµ¬ì¡°]ë¥¼ ë¨¼ì € ì„¤ê³„í•˜ê³ ,
    ê·¸ ì„¤ê³„ë¥¼ ì±„ìš¸ ìµœì ì˜ ì¥ì†Œë¥¼ ë°œêµ´ ë° ê²€ì¦í•˜ëŠ” ì „ëµê°€ ì—ì´ì „íŠ¸.
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(name="SearchAgent", config=config)
        self.search_tool = TavilySearchTool(config=config)
        
        # 1. configì—ì„œ ë¨¼ì € ì°¾ê³ , ì—†ìœ¼ë©´ os.environì—ì„œ ì§ì ‘ ì°¾ìŒ
        self.openai_api_key = self.config.get("openai_api_key") or os.getenv("OPENAI_API_KEY")
        self.google_maps_api_key = self.config.get("google_maps_api_key") or os.getenv("GOOGLE_MAPS_API_KEY")
        self.llm_model = self.config.get("llm_model", "gpt-4o-mini")
        
        # 2. í‚¤ê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        if not self.google_maps_api_key:
            raise ValueError("GOOGLE_MAPS_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì´ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        self.client = AsyncOpenAI(api_key=self.openai_api_key)
        self.gmaps = googlemaps.Client(key=self.google_maps_api_key)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ëµ ìˆ˜ë¦½ -> í–‰ë™ ë¶„í•´ -> ê²€ìƒ‰ -> êµ¬ê¸€ ê²€ì¦ -> í›„ë³´ í’€ ë°˜í™˜"""
        if not self.validate_input(input_data):
            return {"success": False, "error": "ì…ë ¥ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

        theme = input_data.get("theme")
        location = input_data.get("location")
        
        # 1. ì „ëµ ìˆ˜ë¦½ (í–‰ë™ ë¶„ì„ ë° ì¹´í…Œê³ ë¦¬ ì„¤ê³„)
        print(f"\nğŸ§  [Step 1] í…Œë§ˆ ë¶„ì„ ë° ì½”ìŠ¤ ì„¤ê³„ ì¤‘...")
        
        strategy = await self._generate_strategy(theme, location)
        if not strategy:
            return {"success": False, "error": "LLM ì „ëµ ìˆ˜ë¦½ ì‹¤íŒ¨"}
        

        # 2. Tavily ë©€í‹° ê²€ìƒ‰ (ë³¸ë¬¸ ë°ì´í„° í™•ë³´)
        print(f"ğŸ“¡ [Step 2] Tavilyë¥¼ í†µí•´ ë°©ëŒ€í•œ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘... (60ê°œ í›„ë³´ íƒìƒ‰)")

        tasks = [
            self.search_tool.execute(query=step['search_query'], max_results=20) 
            for step in strategy['course_structure']
        ]
        search_results = await asyncio.gather(*tasks)
        
        
        print(f"ğŸ“ [Step 3-1] LLMì´ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì§„ì§œ ì¥ì†Œëª…ë§Œ ì¶”ì¶œ ì¤‘...")
        # 3. LLM ì—”í‹°í‹° ì¶”ì¶œ ë° URL ë³´ì¡´
        all_raw_data = []
        for res in search_results:
            if res["success"]:
                # ì œëª©, ë³¸ë¬¸, URLì„ í•œ ê°ì²´ë¡œ ë¬¶ì–´ì„œ ì „ë‹¬ (ê¸¸ì´ ì œí•œ ì ìš©)
                for p in res["places"]:
                    all_raw_data.append({
                        "url": p["source_url"],
                        "title": self._shrink_text(p.get("name", ""), 120),
                        "snippet": self._shrink_text(p.get("description", ""), 900),
                    })
                
        # ë°ì´í„° ìˆœì„œë¥¼ ì„ì–´ì„œ íŠ¹ì • ì¹´í…Œê³ ë¦¬ ì ë¦¼ ë°©ì§€
        random.shuffle(all_raw_data) 
        print(f"ğŸ“ [Step 3-2] LLMì´ 60ê°œ ì›ë¬¸ ì „ì²´ë¥¼ ì „ìˆ˜ ì¡°ì‚¬ ì¤‘...")
        
        # [Step 3 ìˆ˜ì •] ì´ë¦„ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ í•¨ê»˜ ì¶”ì¶œ
        # ìˆ˜ì •ëœ ì¶”ì¶œ í•¨ìˆ˜ í˜¸ì¶œ
        refined_data = await self._extract_place_entities_with_source(all_raw_data, location)

        #  LLMì˜ ì„±ì‹¤ë„ ì²´í¬
        print(f"   âœ… LLMì´ 60ê°œ ë°ì´í„°ì—ì„œ ë°œêµ´í•œ ìœ ë‹ˆí¬ ì¥ì†Œ: {len(refined_data)}ê°œ")

        # ì¸ê¸°ë„(ì–¸ê¸‰ íšŸìˆ˜) ê³„ì‚°
        # ì–´ë–¤ ì¥ì†Œê°€ 60ê°œ ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ì—¬ëŸ¬ ë²ˆ ë“±ì¥í–ˆëŠ”ì§€ ì¹´ìš´íŠ¸í•©ë‹ˆë‹¤.
        mention_counts = {}
        for item in refined_data:
            name = item.get('name')
            mention_counts[name] = mention_counts.get(name, 0) + 1

        # 4. Google Maps ê¸°ë°˜ ê²€ì¦
        category_buckets = {} # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¥ì†Œë¥¼ ë‹´ì„ ë°”êµ¬ë‹ˆ
        seen_names = set() # ì¤‘ë³µ ì œê±°ìš©

        for item in refined_data:
            # ì´ì œ nameë¿ë§Œ ì•„ë‹ˆë¼ categoryë„ item ì•ˆì— ë“¤ì–´ìˆìŠµë‹ˆë‹¤.
            place_name = item.get('name')
            place_category = item.get('category', 'ê¸°íƒ€') # ê¸°ë³¸ê°’ ì„¤ì •
            
            clean_name = self._clean_place_name(place_name)
            google_info = self._get_google_data(clean_name, location)
    
            # ì¹´í…Œê³ ë¦¬ì— ë”°ë¥¸ ìœ ì—°í•œ í•„í„°ë§
            is_valid = False
            cat = place_category
            
            if google_info:
                g_rating = google_info['rating']
                # [ê°•ë ¥ ì²˜ë°©] í‰ì ì´ 0.1~3.0 ì‚¬ì´ë¼ë©´ 'ì§„ì§œ ë‚˜ìœ ê³³' í˜¹ì€ 'ë¶€ë™ì‚°'ì„. ê°€ì°¨ì—†ì´ ì»¤íŠ¸!
                if 0.1 <= g_rating < 3.0:
                    print(f"   - [Hard Cut] {google_info['name']}: í‰ì  {g_rating} (í’ˆì§ˆ ë¯¸ë‹¬)")
                    continue

                if cat in ['ì‹ë‹¹', 'ì¹´í˜']:
                    if g_rating >= 4.0: is_valid = True
                else:
                    is_valid = True # í‰ì  0.0(ì‹ ê·œ) ì´ê±°ë‚˜ 3.0 ì´ìƒì¸ í™œë™/ê´€ê´‘ì§€ëŠ” í†µê³¼
            
            elif cat in ['í™œë™', 'ê´€ê´‘ì§€', 'ì‡¼í•‘']:
                # êµ¬ê¸€ì— ì—†ì–´ë„ LLMì´ ì¶”ì¶œí–ˆë‹¤ë©´ 'ìµœì‹  íŒì—…'ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œ í†µê³¼
                is_valid = True
                google_info = {"name": place_name, "rating": 0.0, "reviews_count": 0, "address": "ì£¼ì†Œ ì •ë³´ í™•ì¸ í•„ìš”"}
            
            
            if is_valid:
                g_name = google_info['name']
                if g_name in seen_names: continue

                # all_raw_dataì—ì„œ ì´ ì¥ì†Œì˜ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì•„ì˜µë‹ˆë‹¤.
                # item['source_url']ê³¼ ì¼ì¹˜í•˜ëŠ” ì›ë¬¸ì„ ê²€ìƒ‰
                original_desc = ""
                for raw in all_raw_data:
                    if raw['url'] == item.get('source_url'):
                        # titleê³¼ snippetì„ ì¡°í•©í•˜ì—¬ ì›ë³¸ í…ìŠ¤íŠ¸ ì¬êµ¬ì„±
                        original_desc = f"{raw.get('title', '')} {raw.get('snippet', '')}".strip()
                        break
 
                # [V3 ì—…ê·¸ë ˆì´ë“œ] ì–¸ê¸‰ íšŸìˆ˜(Mentions)ë¥¼ ì ìˆ˜ ê³„ì‚°ê¸°ì— ì „ë‹¬
                trust_score = self._calculate_trust_score_v3(
                    google_info['rating'], 
                    google_info['reviews_count'], 
                    original_desc, 
                    cat,
                    mention_counts.get(place_name, 1) # ì–¸ê¸‰ íšŸìˆ˜ ì¶”ê°€
                )

                # ğŸ”— URL ì¸ì½”ë”© ì²˜ë¦¬ (ê³µë°±ì„ +ë¡œ ì¹˜í™˜í•˜ì—¬ í´ë¦­ ê°€ëŠ¥í•˜ê²Œ)
                encoded_name = g_name.replace(" ", "+")
                map_url = f"https://www.google.com/maps/search/?api=1&query={encoded_name}+{location.replace(' ', '+')}"

                #print(f"   - [Keep] {google_info['name']} (í‰ì : {google_info['rating']})")
                
                place_obj = {
                    "name": g_name,
                    "category": cat,
                    "rating": google_info['rating'],
                    "trust_score": trust_score,
                    "address": google_info['address'],
                    "source_url": item.get('source_url'),
                    "map_url": map_url
                }

                # [í•µì‹¬ ì¶”ê°€] ë°”êµ¬ë‹ˆì— ë‹´ê¸°
                if cat not in category_buckets:
                    category_buckets[cat] = []
                category_buckets[cat].append(place_obj)

                seen_names.add(g_name)


        # ============================================================
        # 5. [ë¼ìš´ë“œ ë¡œë¹ˆ ì„ ë°œ] ë‹¤ì–‘ì„± ë³´ì¥ ë¡œì§
        # ============================================================
        final_pool = []
        TOTAL_LIMIT = 15

        # ê° ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ ì ìˆ˜ ìˆœìœ¼ë¡œ ë¯¸ë¦¬ ì •ë ¬
        for cat in category_buckets:
            category_buckets[cat].sort(key=lambda x: x['trust_score'], reverse=True)

        # 1ì°¨ ëª©í‘œ: ì „ëµ ì¹´í…Œê³ ë¦¬ (Step 2ì—ì„œ ì„¤ê³„í•œ 3ê°œ)
        strategic_cats = [step['category'] for step in strategy['course_structure']]
        # 2ì°¨ ëª©í‘œ: ë‚˜ë¨¸ì§€ ì¹´í…Œê³ ë¦¬
        other_cats = [c for c in category_buckets.keys() if c not in strategic_cats]
        
        # ì „ì²´ ìˆœíšŒ ìˆœì„œ: [ì „ëµ1, ì „ëµ2, ì „ëµ3, ê¸°íƒ€1, ê¸°íƒ€2...]
        ordered_cats = strategic_cats + other_cats

        # â— [í•µì‹¬] í•œ ë°”í€´ ëŒ ë•Œë§ˆë‹¤ 'ë”± í•œ ê°œì”©'ë§Œ ë½‘ìŠµë‹ˆë‹¤.
        while len(final_pool) < TOTAL_LIMIT:
            added_in_this_round = False
            
            for cat in ordered_cats:
                if len(final_pool) >= TOTAL_LIMIT: break
                
                if cat in category_buckets and category_buckets[cat]:
                    final_pool.append(category_buckets[cat].pop(0))
                    added_in_this_round = True
            
            # ëª¨ë“  ë°”êµ¬ë‹ˆê°€ ë¹„ì—ˆìœ¼ë©´ ì¢…ë£Œ
            if not added_in_this_round:
                break

        # ì¤‘ë³µ ì œê±° (ì´ë¦„ ê¸°ì¤€)
        seen = set()
        unique_final_pool = []
        for p in final_pool:
            if p['name'] not in seen:
                unique_final_pool.append(p)
                seen.add(p['name'])
        
        final_pool = unique_final_pool[:TOTAL_LIMIT]
        
        # SearchAgent.execute()ì˜ ë¦¬í„´ê°’ ë‹¤ìŒ ì—ì´ì „íŠ¸ì—ê²Œ ì¤„ 'ìµœì¢… íŒ¨í‚¤ì§€'
        return {
            "success": True,
            "agent_name": self.name,
            "action_analysis": strategy.get('action_analysis'),
            "candidate_pool": final_pool,
            "user_intent": {
                "course_structure": strategy.get('course_structure'),
                # ì—¬ê¸°ì— reasoning ì •ë³´ê°€ stepë³„ë¡œ í¬í•¨ë˜ì–´ ìˆì–´ ë°ì´í„°ê°€ íœ˜ë°œë˜ì§€ ì•ŠìŒ
                "raw_theme": theme,
                "location": location
            }
        }
    

    # async def _extract_place_entities_with_source(self, raw_data: List[Dict], location: str) -> List[Dict]:
    #     """
    #     [ë²”ìš© ê³ ë„í™”] ì–´ë–¤ í…Œë§ˆì—ì„œë„ 60ê°œ ë°ì´í„°ë¥¼ ìƒ…ìƒ…ì´ ë’¤ì ¸ ìµœëŒ€í•œ ë§ì€ ì¥ì†Œë¥¼ ë°œêµ´í•¨.
    #     ë°°ì¹˜ ì²˜ë¦¬ë¡œ í† í° ì œí•œ ë¬¸ì œ í•´ê²°.
    #     """
    #     if not raw_data: return []
        
    #     # ë°°ì¹˜ í¬ê¸° ì„¤ì • (í† í° ì œí•œ ê³ ë ¤: gpt-4o-miniëŠ” 8192 í† í° ì œí•œì´ë¯€ë¡œ 6-8ê°œì”© ì²˜ë¦¬)
    #     BATCH_SIZE = 6
    #     all_results = []
        
    #     # ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
    #     batches = [raw_data[i:i + BATCH_SIZE] for i in range(0, len(raw_data), BATCH_SIZE)]
    #     total_batches = len(batches)
        
    #     print(f"   ğŸ“¦ ì´ {len(raw_data)}ê°œ ë°ì´í„°ë¥¼ {total_batches}ê°œ ë°°ì¹˜ë¡œ ë‚˜ëˆ  ì²˜ë¦¬í•©ë‹ˆë‹¤...")
        
    #     # ê° ë°°ì¹˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
    #     for batch_idx, batch_data in enumerate(batches, 1):
    #         print(f"   ğŸ”„ ë°°ì¹˜ {batch_idx}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch_data)}ê°œ ë°ì´í„°)")
            
    #         try:
    #             batch_results = await self._process_batch(batch_data, location, batch_idx, total_batches)
    #             if batch_results:
    #                 all_results.extend(batch_results)
    #         except Exception as e:
    #             print(f"   âš ï¸  ë°°ì¹˜ {batch_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    #             continue
        
    #     # ì¤‘ë³µ ì œê±° (ê°™ì€ ì¥ì†Œëª…, ê°™ì€ URL)
    #     unique_results = []
    #     seen = set()
    #     for item in all_results:
    #         key = (item.get('name', ''), item.get('source_url', ''))
    #         if key not in seen and key[0]:  # ì´ë¦„ì´ ìˆëŠ” ê²½ìš°ë§Œ
    #             seen.add(key)
    #             unique_results.append(item)
        
    #     return unique_results
    
    async def _extract_place_entities_with_source(self, raw_data: List[Dict], location: str) -> List[Dict]:
        """
        [ë³‘ë ¬ ê³ ë„í™”] 60ê°œ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ  'ë™ì‹œì—' LLMì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.
        ì •í™•ë„ëŠ” ìœ ì§€í•˜ê³  ì†ë„ëŠ” 10ë°° í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        """
        if not raw_data: return []
        
        # 1. ë°°ì¹˜ í¬ê¸° ì„¤ì •
        BATCH_SIZE = 6
        batches = [raw_data[i:i + BATCH_SIZE] for i in range(0, len(raw_data), BATCH_SIZE)]
        total_batches = len(batches)
        
        print(f"   ğŸš€ ì´ {len(raw_data)}ê°œ ë°ì´í„°ë¥¼ {total_batches}ê°œ ë°°ì¹˜ë¡œ 'ë³‘ë ¬' ë§ˆì´ë‹ ì‹œì‘...")
        
        # 2. [í•µì‹¬] ë¹„ë™ê¸° íƒœìŠ¤í¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        # ê° ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‹¤í–‰ ì˜ˆì•½(Task) ìƒíƒœë¡œ ë§Œë“­ë‹ˆë‹¤.
        tasks = [
            self._process_batch(batch_data, location, i + 1, total_batches)
            for i, batch_data in enumerate(batches)
        ]
        
        # 3. [í•µì‹¬] ë™ì‹œì— ì‹¤í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘
        # asyncio.gatherëŠ” ëª¨ë“  íƒœìŠ¤í¬ê°€ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¸ë‹¤ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        batch_results_list = await asyncio.gather(*tasks)
        
        # 4. ê²°ê³¼ í†µí•©
        all_results = []
        for batch_results in batch_results_list:
            if batch_results:
                all_results.extend(batch_results)
        
        # 5. ì¤‘ë³µ ì œê±° (ì´ë¦„ê³¼ URL ê¸°ì¤€)
        unique_results = []
        seen = set()
        for item in all_results:
            key = (item.get('name', '').strip(), item.get('source_url', ''))
            if key not in seen and key[0]:
                seen.add(key)
                unique_results.append(item)
        
        print(f"   âœ… ë³‘ë ¬ ë§ˆì´ë‹ ì™„ë£Œ: ì´ {len(unique_results)}ê°œì˜ ìœ ë‹ˆí¬ ì¥ì†Œ ë°œêµ´")
        return unique_results
    
    async def _process_batch(self, batch_data: List[Dict], location: str, batch_num: int, total_batches: int) -> List[Dict]:
        """ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬"""
        prompt = f"""
        ë‹¹ì‹ ì€ ë°©ëŒ€í•œ ì›¹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¹˜ ìˆëŠ” ì¥ì†Œ ì •ë³´ë§Œ ê³¨ë¼ë‚´ëŠ” 'ì—¬í–‰ ì •ë³´ ë§ˆì´ë‹ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤. 
        ì œê³µëœ {len(batch_data)}ê°œì˜ ê²€ìƒ‰ ê²°ê³¼(ë°°ì¹˜ {batch_num}/{total_batches})ì—ì„œ {location} ì§€ì—­ì˜ ì§„ì§œ 'ì¥ì†Œëª…'ì„ ì¶”ì¶œí•˜ê³  ë¶„ë¥˜í•˜ì„¸ìš”.

        [ì„ë¬´ 1: ë°ì´í„° ì •ì œ ë° ì¤‘ë³µ ì œê±° (í•„ìˆ˜)]
        - ë™ì¼í•œ ì¥ì†Œê°€ ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì— ë‚˜íƒ€ë‚  ê²½ìš°, ê°€ì¥ ì •ë³´ê°€ ì•Œì°¬ í•˜ë‚˜ì˜ ê²°ê³¼ë¡œ í†µí•©í•˜ì„¸ìš”.
        - ìˆ˜ì‹ì–´ì™€ ì¼ë°˜ ëª…ì‚¬ë¥¼ ì œê±°í•œ 'ìˆœìˆ˜ ìƒí˜¸ëª…'ë§Œ ë‚¨ê¸°ì„¸ìš”. (ì˜ˆ: 'ì„±ìˆ˜ë™ í•«í”Œ ì¹´í˜ ì–´ë‹ˆì–¸' -> 'ì–´ë‹ˆì–¸')
        - í•œ í¬ìŠ¤íŒ…/ê¸°ì‚¬ì— ì—¬ëŸ¬ ì¥ì†Œ(ì˜ˆ: í˜œí™” ë§›ì§‘ 5ê³³ ë¦¬ìŠ¤íŠ¸)ê°€ ìˆë‹¤ë©´ **ë°˜ë“œì‹œ ëª¨ë“  ì¥ì†Œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œ**í•˜ì„¸ìš”.

        [ì„ë¬´ 2: ì—„ê²©í•œ í•„í„°ë§]
        - 'ë§›ì§‘', 'ì½”ìŠ¤', 'ì—¬í–‰ì§€', 'ë°ì´íŠ¸ ì¥ì†Œ'ì™€ ê°™ì€ ì¼ë°˜ ëª…ì¹­ì€ ì¥ì†Œëª…ì—ì„œ ì œì™¸í•˜ì„¸ìš”.
        - êµ¬ê¸€ ì§€ë„ì—ì„œ ê²€ìƒ‰í–ˆì„ ë•Œ ì •í™•íˆ ìœ„ì¹˜ê°€ ë‚˜ì˜¬ ë²•í•œ ê³ ìœ  ëª…ì‚¬ì—¬ì•¼ í•©ë‹ˆë‹¤.
        - 'ê´€ê´‘ê°ì´ ì§ì ‘ ë°©ë¬¸í•˜ì—¬ ì‹œê°„ì„ ë³´ë‚¼ ìˆ˜ ìˆëŠ” ì‹¤ì²´ê°€ ìˆëŠ” ì¥ì†Œ'ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
        - ì œì™¸ ëŒ€ìƒ: ë¶€ë™ì‚°, ì¶”ì§„ìœ„ì›íšŒ, ì•„íŒŒíŠ¸ ë‹¨ì§€ëª…, ë‹¨ìˆœ ì§€ì—­ëª…, ê³µê³µê¸°ê´€, ê¸°ì—… ì‚¬ë¬´ì‹¤.

        [ì„ë¬´ 3: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì§€ì¹¨ (ë²”ìš©)]
        ì•„ë˜ ë¦¬ìŠ¤íŠ¸ ì¤‘ ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”: [ì‹ë‹¹, ì¹´í˜, í™œë™, ì‡¼í•‘, ìˆ™ì†Œ, ê´€ê´‘ì§€, ê¸°íƒ€]
        - ì‹ë‹¹: ë°¥ì§‘, ë ˆìŠ¤í† ë‘, ì£¼ì , ìš”ë¦¬ ì¤‘ì‹¬ ê³µê°„
        - ì¹´í˜: ì»¤í”¼, ë””ì €íŠ¸, ë² ì´ì»¤ë¦¬, ì°»ì§‘
        - í™œë™: ì—°ê·¹, ë®¤ì§€ì»¬, ì†Œê·¹ì¥, ë°©íƒˆì¶œ, ê³µë°©, ì „ì‹œíšŒ, ì›ë°ì´í´ë˜ìŠ¤, íŒì—…ìŠ¤í† ì–´, ìŠ¤í¬ë¦°ìŠ¤í¬ì¸  ë“± 'ì²´í—˜' ì¤‘ì‹¬ ê³µê°„.
        - ê´€ê´‘ì§€: ê³µì›, í•´ìˆ˜ìš•ì¥, ìœ ì ì§€, ëœë“œë§ˆí¬ ë“± 'ê´€ëŒ/í’ê²½' ì¤‘ì‹¬ ê³µê°„.
        - ì‡¼í•‘: í¸ì§‘ìƒµ, ì†Œí’ˆìƒµ, ë°±í™”ì  ë“± ë¬¼ê±´ êµ¬ë§¤ ê³µê°„.
        - ì¶œì²˜: í•´ë‹¹ ì¥ì†Œê°€ ì–¸ê¸‰ëœ ë°ì´í„°ì˜ 'url' í•„ë“œ ê°’ì„ ì •í™•íˆ ë§¤ì¹­í•˜ì„¸ìš”.

        [ì„ë¬´ 4: ì „ìˆ˜ ì¡°ì‚¬ ëª…ë ¹ (ì¤‘ìš”)]
        - ì œê³µëœ ë°ì´í„°ë¥¼ ì ˆëŒ€ë¡œ ëŒ€ì¶© í›‘ì§€ ë§ˆì„¸ìš”. 
        - ê° ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ëê¹Œì§€ ì½ê³  ìˆ¨ê²¨ì§„ ì¥ì†Œëª…ì„ ëª¨ë‘ ì°¾ì•„ë‚´ì„¸ìš”.
        - ê²°ê³¼ê°€ ë§ì•„ë„ ì¢‹ìœ¼ë‹ˆ ëˆ„ë½ë˜ëŠ” ì¥ì†Œê°€ ì—†ê²Œ í•˜ëŠ” ê²ƒì´ ìµœìš°ì„ ì…ë‹ˆë‹¤.

        [ë¶„ì„í•  ë°ì´í„°]
        ê° ë°ì´í„°ëŠ” ë‹¤ìŒ í˜•ì‹ì…ë‹ˆë‹¤:
        - url: ì¶œì²˜ URL
        - title: ì œëª© (ìµœëŒ€ 120ì)
        - snippet: ë³¸ë¬¸ ìš”ì•½ (ìµœëŒ€ 900ì)
        
        {batch_data}

        [ì‘ë‹µ í˜•ì‹]
        **ë°˜ë“œì‹œ ë‹¤ìŒì˜ JSON í˜•ì‹ë§Œ** ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        
        ```json
        {{
          "results": [
            {{
              "name": "ì¥ì†Œëª…",
              "category": "ì¹´í…Œê³ ë¦¬",
              "source_url": "ë°ì´í„°ì— ì œê³µëœ ì‹¤ì œ url"
            }}
          ]
        }}
        ```
        
        **ì¤‘ìš”: JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**
        """
        
        try:
            response = await self.client.chat.completions.create(
                model=self.llm_model,
                messages=[{"role": "system", "content": "You are a professional travel data miner who never skips info. Output only JSON."},
                          {"role": "user", "content": prompt}],
                max_tokens=1500,  # ì¥ì†Œëª… ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œì—ëŠ” 1500 í† í°ìœ¼ë¡œ ì¶©ë¶„ (ì…ë ¥ í† í° ì—¬ìœ  í™•ë³´)
                temperature=0.3  # ì¼ê´€ëœ JSON í˜•ì‹ ìœ ì§€
            )
            
            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
            response_content = response.choices[0].message.content.strip()
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            if "```json" in response_content:
                json_start = response_content.find("```json") + 7
                json_end = response_content.find("```", json_start)
                if json_end == -1:
                    json_end = len(response_content)
                response_content = response_content[json_start:json_end].strip()
            elif "```" in response_content:
                json_start = response_content.find("```") + 3
                json_end = response_content.find("```", json_start)
                if json_end == -1:
                    json_end = len(response_content)
                response_content = response_content[json_start:json_end].strip()
            
            # JSON ê°ì²´ ì‹œì‘/ë ì°¾ê¸° (ì¤‘ê´„í˜¸ ê¸°ì¤€)
            json_start_idx = response_content.find("{")
            json_end_idx = response_content.rfind("}") + 1
            if json_start_idx != -1 and json_end_idx > json_start_idx:
                response_content = response_content[json_start_idx:json_end_idx]
            
            # JSON íŒŒì‹± (ë” ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬)
            try:
                data = json.loads(response_content)
                results = data.get("results", [])
                print(f"      âœ… ë°°ì¹˜ {batch_num}ì—ì„œ {len(results)}ê°œ ì¥ì†Œ ì¶”ì¶œ ì™„ë£Œ")
                return results
            except json.JSONDecodeError as e:
                # JSON íŒŒì‹± ì˜¤ë¥˜ ì‹œ ì‘ë‹µ ë‚´ìš©ì—ì„œ JSON ë¶€ë¶„ì„ ë” ì ê·¹ì ìœ¼ë¡œ ì°¾ê¸°
                print(f"      âš ï¸  ë°°ì¹˜ {batch_num} JSON íŒŒì‹± ì˜¤ë¥˜ ì‹œë„ ì¤‘... (ì˜¤ë¥˜: {str(e)[:100]})")
                
                # ë°©ë²• 1: ì²« ë²ˆì§¸ { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€ ë‹¤ì‹œ ì¶”ì¶œ
                try:
                    first_brace = response_content.find('{')
                    last_brace = response_content.rfind('}')
                    if first_brace != -1 and last_brace > first_brace:
                        cleaned_json = response_content[first_brace:last_brace+1]
                        data = json.loads(cleaned_json)
                        results = data.get("results", [])
                        print(f"      âœ… ë°°ì¹˜ {batch_num} ë³µêµ¬ ì„±ê³µ (ë°©ë²•1): {len(results)}ê°œ ì¥ì†Œ ì¶”ì¶œ")
                        return results
                except Exception as e1:
                    pass
                
                # ë°©ë²• 2: ë¶ˆì™„ì „í•œ JSON ë³µêµ¬ ì‹œë„ (ë‹«íˆì§€ ì•Šì€ ë¬¸ìì—´/ë°°ì—´ ìˆ˜ì •)
                try:
                    # JSONì´ ì¤‘ê°„ì— ì˜ë¦° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë³µêµ¬ ì‹œë„
                    first_brace = response_content.find('{')
                    if first_brace != -1:
                        # "results" ë°°ì—´ì´ ìˆëŠ”ì§€ í™•ì¸
                        if '"results"' in response_content:
                            # ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ê¹Œì§€ ì°¾ê¸°
                            json_part = response_content[first_brace:]
                            
                            # ë‹«íˆì§€ ì•Šì€ ë¬¸ìì—´ ë‹«ê¸°
                            if json_part.count('"') % 2 != 0:
                                json_part += '"'
                            
                            # ë‹«íˆì§€ ì•Šì€ ë°°ì—´/ê°ì²´ ë‹«ê¸°
                            open_braces = json_part.count('{')
                            close_braces = json_part.count('}')
                            open_brackets = json_part.count('[')
                            close_brackets = json_part.count(']')
                            
                            # ë¶€ì¡±í•œ ë‹«ëŠ” ê´„í˜¸ ì¶”ê°€
                            json_part += '}' * (open_braces - close_braces)
                            json_part += ']' * (open_brackets - close_brackets)
                            
                            # ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±° (ì˜ëª»ëœ JSON í˜•ì‹ ë°©ì§€)
                            json_part = json_part.rstrip().rstrip(',')
                            if not json_part.endswith('}'):
                                json_part += '}'
                            
                            data = json.loads(json_part)
                            results = data.get("results", [])
                            if results:
                                print(f"      âœ… ë°°ì¹˜ {batch_num} ë³µêµ¬ ì„±ê³µ (ë°©ë²•2): {len(results)}ê°œ ì¥ì†Œ ì¶”ì¶œ")
                                return results
                except Exception as e2:
                    pass
                
                # ë°©ë²• 3: ì •ê·œì‹ìœ¼ë¡œ JSON ê°ì²´ ì¶”ì¶œ ì‹œë„
                try:
                    import re
                    # "results" ë°°ì—´ ë‚´ì˜ ê°ì²´ë“¤ë§Œ ì¶”ì¶œ
                    pattern = r'\{[^{}]*"name"\s*:\s*"[^"]*"[^{}]*"category"\s*:\s*"[^"]*"[^{}]*"source_url"\s*:\s*"[^"]*"[^{}]*\}'
                    matches = re.findall(pattern, response_content, re.DOTALL)
                    if matches:
                        results = []
                        for match in matches:
                            try:
                                obj = json.loads(match)
                                if "name" in obj and "category" in obj:
                                    results.append(obj)
                            except:
                                continue
                        if results:
                            print(f"      âœ… ë°°ì¹˜ {batch_num} ë³µêµ¬ ì„±ê³µ (ë°©ë²•3): {len(results)}ê°œ ì¥ì†Œ ì¶”ì¶œ")
                            return results
                except Exception as e3:
                    pass
                
                # ëª¨ë“  ë³µêµ¬ ì‹œë„ ì‹¤íŒ¨
                print(f"      âŒ ë°°ì¹˜ {batch_num} JSON íŒŒì‹± ì‹¤íŒ¨ (ì‘ë‹µ ê¸¸ì´: {len(response_content)}, ì¼ë¶€: {response_content[:300]})")
                # ë””ë²„ê¹…ì„ ìœ„í•´ ì „ì²´ ì‘ë‹µ ì €ì¥ (ì„ íƒì‚¬í•­)
                if len(response_content) < 2000:  # ë„ˆë¬´ ê¸¸ì§€ ì•Šìœ¼ë©´ ì „ì²´ ì¶œë ¥
                    print(f"      ğŸ“‹ ì „ì²´ ì‘ë‹µ: {response_content}")
                return []
                
        except Exception as e:
            error_msg = str(e)
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼ ì˜¤ë¥˜ ì²˜ë¦¬
            if "context length" in error_msg.lower() or "8192" in error_msg or "maximum context" in error_msg.lower():
                print(f"      âš ï¸  ë°°ì¹˜ {batch_num} ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ ì¬ì‹œë„...")
                # ë°°ì¹˜ë¥¼ ë” ì‘ê²Œ ë‚˜ëˆ„ì–´ ì¬ì‹œë„
                if len(batch_data) > 3:
                    mid = len(batch_data) // 2
                    first_half = batch_data[:mid]
                    second_half = batch_data[mid:]
                    
                    results = []
                    if first_half:
                        sub_results = await self._process_batch(first_half, location, batch_num * 100, total_batches)
                        results.extend(sub_results)
                    if second_half:
                        sub_results = await self._process_batch(second_half, location, batch_num * 100 + 1, total_batches)
                        results.extend(sub_results)
                    return results
                else:
                    print(f"      âš ï¸  ë°°ì¹˜ {batch_num}ê°€ ë„ˆë¬´ ì‘ì•„ë„ ì‹¤íŒ¨. ê±´ë„ˆëœë‹ˆë‹¤.")
                    return []
            
            # Rate limit ì˜¤ë¥˜ ì²˜ë¦¬
            elif "rate_limit" in error_msg.lower() or "429" in error_msg:
                print(f"      âš ï¸  ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì¤‘ í† í° ì œí•œ ì´ˆê³¼. ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                import asyncio
                await asyncio.sleep(3)  # 3ì´ˆ ëŒ€ê¸°
                # ì¬ì‹œë„
                try:
                    response = await self.client.chat.completions.create(
                        model=self.llm_model,
                        messages=[{"role": "system", "content": "You are a professional travel data miner who never skips info. Output only JSON."},
                                  {"role": "user", "content": prompt}],
                        max_tokens=1500,
                        temperature=0.3
                    )
                    response_content = response.choices[0].message.content.strip()
                    
                    if "```json" in response_content:
                        json_start = response_content.find("```json") + 7
                        json_end = response_content.find("```", json_start)
                        if json_end == -1:
                            json_end = len(response_content)
                        response_content = response_content[json_start:json_end].strip()
                    elif "```" in response_content:
                        json_start = response_content.find("```") + 3
                        json_end = response_content.find("```", json_start)
                        if json_end == -1:
                            json_end = len(response_content)
                        response_content = response_content[json_start:json_end].strip()
                    
                    json_start_idx = response_content.find("{")
                    json_end_idx = response_content.rfind("}") + 1
                    if json_start_idx != -1 and json_end_idx > json_start_idx:
                        response_content = response_content[json_start_idx:json_end_idx]
                    
                    data = json.loads(response_content)
                    results = data.get("results", [])
                    print(f"      âœ… ë°°ì¹˜ {batch_num} ì¬ì‹œë„ ì„±ê³µ: {len(results)}ê°œ ì¥ì†Œ ì¶”ì¶œ")
                    return results
                except Exception as retry_e:
                    print(f"      âš ï¸  ë°°ì¹˜ {batch_num} ì¬ì‹œë„ ì‹¤íŒ¨: {str(retry_e)[:100]}")
                    return []
            else:
                print(f"      âš ï¸  ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {error_msg[:150]}")
                return []  

    #(ì˜ˆ: ëŒ€í™” ì¤‘ì‹¬, í™œë™ ì¤‘ì‹¬, íœ´ì‹ ì¤‘ì‹¬)
    #(ì˜ˆ: ì¡°ìš©í•œ ì¹´í˜, ì‹¤ë‚´ ì „ì‹œì¥, ë¶„ìœ„ê¸° ìˆëŠ” ì‹ë‹¹)

    async def _generate_strategy(self, theme: str, location: str) -> Optional[Dict]:
        """
        [ìµœì¢… ê³ ë„í™”] ì‹œìŠ¤í…œ í‘œì¤€ ì¹´í…Œê³ ë¦¬ì™€ ì „ëµì„ ì¼ì¹˜ì‹œì¼œ ë°ì´í„° ìœ ì‹¤ì„ ë°©ì§€í•¨.
        """
        # ì‹œìŠ¤í…œì—ì„œ ì •ì˜í•œ 7ê°œ í‘œì¤€ ì¹´í…Œê³ ë¦¬ (Step 3ì˜ ë¶„ë¥˜ì™€ ì¼ì¹˜ì‹œì¼œì•¼ í•¨)
        valid_categories = ["ì‹ë‹¹", "ì¹´í˜", "í™œë™", "ì‡¼í•‘", "ìˆ™ì†Œ", "ê´€ê´‘ì§€", "ê¸°íƒ€"]

        prompt = f"""
        ë‹¹ì‹ ì€ ë² í…Œë‘ ì—¬í–‰ ì„¤ê³„ìì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ í…Œë§ˆë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ 'ì½”ìŠ¤ êµ¬ì¡°'ë¥¼ ì„¤ê³„í•˜ê³ , ê° êµ¬ì¡°ë¥¼ ì±„ìš¸ ê²€ìƒ‰ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

        [ì‚¬ìš©ì ì…ë ¥]
        - í…Œë§ˆ: {theme}
        - ì§€ì—­: {location}

        [ì„ë¬´]
        1. ì´ í…Œë§ˆì— í•„ìš”í•œ 'í–‰ë™ íƒ€ì…(Action Types)'ì„ 3ê°€ì§€ ë¶„ì„í•˜ì„¸ìš”. 
        2. ê° í–‰ë™ì„ ë§Œì¡±í•˜ê¸° ìœ„í•´ ì•„ë˜ [í‘œì¤€ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸] ì¤‘ ê°€ì¥ ì í•©í•œ ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ì”© ë§¤ì¹­í•˜ì„¸ìš”.
           - í‘œì¤€ ì¹´í…Œê³ ë¦¬: {valid_categories}
        
        3. ê° ë‹¨ê³„ë³„ë¡œ Tavily ê²€ìƒ‰ì„ ìœ„í•œ 'ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬'ì™€ ê·¸ ì¿¼ë¦¬ë¥¼ ì„ ì •í•œ 'íŒë‹¨ ê·¼ê±°(reasoning)'ë¥¼ ìƒì„±í•˜ì„¸ìš”.
           (íŒ: 'ì¶”ì²œ', 'ë¦¬ìŠ¤íŠ¸', 'ë¦¬ë·°', 'ë² ìŠ¤íŠ¸' ê°™ì€ ë‹¨ì–´ë¥¼ ì„ì–´ì•¼ êµ¬ì²´ì ì¸ ê°€ê²Œ ì´ë¦„ì´ ì˜ ë‚˜ì˜µë‹ˆë‹¤.)

        [ì‘ë‹µ í˜•ì‹]
        **ë°˜ë“œì‹œ ë‹¤ìŒì˜ JSON í˜•ì‹ë§Œ** ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        
        ```json
        {{
          "action_analysis": "í–‰ë™ íƒ€ì… ë¶„ì„ ìš”ì•½",
          "course_structure": [
            {{
              "step": 1, 
              "category": "ìœ„ í‘œì¤€ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜", 
              "search_query": "íŒŒì›Œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²€ìƒ‰ì–´", 
              "reasoning": "ì´ ì¿¼ë¦¬ë¥¼ ì„ ì •í•œ ì´ìœ "
            }},
            {{
              "step": 2, 
              "category": "ìœ„ í‘œì¤€ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜", 
              "search_query": "íŒŒì›Œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²€ìƒ‰ì–´", 
              "reasoning": "ì´ ì¿¼ë¦¬ë¥¼ ì„ ì •í•œ ì´ìœ "
            }},
            {{
              "step": 3, 
              "category": "ìœ„ í‘œì¤€ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜", 
              "search_query": "íŒŒì›Œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²€ìƒ‰ì–´", 
              "reasoning": "ì´ ì¿¼ë¦¬ë¥¼ ì„ ì •í•œ ì´ìœ "
            }}
          ]
        }}
        ```
        
        **ì¤‘ìš”: JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**
        """
        try:
            response = await self.client.chat.completions.create(
                model=self.llm_model,
                messages=[{"role": "user", "content": prompt}]
            )
            
            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
            response_content = response.choices[0].message.content.strip()
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            if "```json" in response_content:
                json_start = response_content.find("```json") + 7
                json_end = response_content.find("```", json_start)
                if json_end == -1:
                    json_end = len(response_content)
                response_content = response_content[json_start:json_end].strip()
            elif "```" in response_content:
                json_start = response_content.find("```") + 3
                json_end = response_content.find("```", json_start)
                if json_end == -1:
                    json_end = len(response_content)
                response_content = response_content[json_start:json_end].strip()
            
            # JSON ê°ì²´ ì‹œì‘/ë ì°¾ê¸° (ì¤‘ê´„í˜¸ ê¸°ì¤€)
            json_start_idx = response_content.find("{")
            json_end_idx = response_content.rfind("}") + 1
            if json_start_idx != -1 and json_end_idx > json_start_idx:
                response_content = response_content[json_start_idx:json_end_idx]
            
            # JSON íŒŒì‹±
            try:
                return json.loads(response_content)
            except json.JSONDecodeError as e:
                raise ValueError(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}\nì‘ë‹µ ë‚´ìš©: {response_content[:500]}")

        except Exception as e:
            print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨(ì¿¼í„° ì´ˆê³¼ ë“±): {e}")
            # Mock ë°ì´í„°ì—ì„œë„ í‘œì¤€ ì¹´í…Œê³ ë¦¬ ëª…ì¹­ì„ ì‚¬ìš©í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
            return {
                "action_analysis": f"{theme}ì„(ë¥¼) ìœ„í•œ ì‹¤ë‚´ì™¸ í˜¼í•© í™œë™ ë° ë™ì„  ìµœì í™” ì „ëµ",
                "course_structure": [
                    {
                        "step": 1, "category": "ì¹´í˜", 
                        "search_query": f"{location} {theme} ë¶„ìœ„ê¸° ì¢‹ì€ ì¹´í˜ ì¶”ì²œ",
                        "reasoning": "í…Œë§ˆì— ë§ëŠ” ì•„ëŠ‘í•œ ë¶„ìœ„ê¸° í˜•ì„±ì„ ìœ„í•´ ì²« ë²ˆì§¸ ì½”ìŠ¤ë¡œ ì„ ì •"
                    },
                    {
                        "step": 2, "category": "í™œë™", 
                        "search_query": f"{location} {theme} ì‹¤ë‚´ ë†€ê±°ë¦¬ ì „ì‹œ ë² ìŠ¤íŠ¸",
                        "reasoning": "ì§€ë£¨í•¨ì„ ë°©ì§€í•˜ê³  í…Œë§ˆì˜ í•µì‹¬ ê²½í—˜ì„ ì œê³µí•˜ê¸° ìœ„í•œ ë©”ì¸ í™œë™ ì„ ì •"
                    },
                    {
                        "step": 3, "category": "ì‹ì‚¬", 
                        "search_query": f"{location} {theme} ë§›ì§‘ ë¦¬ìŠ¤íŠ¸ ë¦¬ë·°",
                        "reasoning": "í™œë™ í›„ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬ë¥¼ ìœ„í•œ í˜„ì§€ ì¸ê¸° ì‹ë‹¹ íƒìƒ‰"
                    }
                ]
            }

    def _shrink_text(self, text: str, limit: int = 900) -> str:
        """
        ë³¸ë¬¸ í­ì£¼ ë°©ì§€: ê³µë°± ì •ë¦¬ + ê¸¸ì´ ì œí•œ
        Tavilyì—ì„œ ë°›ì€ ê¸´ descriptionì„ í† í° ì˜ˆì‚° ë‚´ë¡œ ì œí•œ
        """
        if not text:
            return ""
        # ì—°ì† ê³µë°±ì„ í•˜ë‚˜ë¡œ ì •ë¦¬
        text = " ".join(text.split())
        # ê¸¸ì´ ì œí•œ
        if len(text) > limit:
            return text[:limit] + "â€¦"
        return text

    ## í•œë²ˆ ì¶”ê°€í•´ë³´ëŠ” ì²­ì†Œê¸°
    def _clean_place_name(self, raw_name: str) -> str:
        """
        ë¸”ë¡œê·¸ ì œëª© ë“±ì—ì„œ ì‹¤ì œ ê°€ê²Œ ì´ë¦„ë§Œ ë‚¨ê¸°ê¸° ìœ„í•œ ì²­ì†Œê¸°
        ì˜ˆ: 'ì„±ìˆ˜ë™ ì¹´í˜ ë² ì´í¬ëª¨êµ´ ì‹¤ë‚´ ë†€ê±°ë¦¬ - ë„¤ì´ë²„ ë¸”ë¡œê·¸' -> 'ë² ì´í¬ëª¨êµ´'
        """
        # 1. í”í•œ ìˆ˜ì‹ì–´ ë° í”Œë«í¼ ì´ë¦„ ì œê±°
        junk_words = [
            'ë„¤ì´ë²„ ë¸”ë¡œê·¸', 'ë„¤ì´ë²„ í¬ìŠ¤íŠ¸', 'í‹°ìŠ¤í† ë¦¬', 'ì¸ìŠ¤íƒ€ê·¸ë¨', 'Instagram',
            'ìœ íŠœë¸Œ', 'YouTube', 'íŠ¸ë¦½ë‹·ì»´', 'ë‚˜ë¬´ìœ„í‚¤', 'ì´ì •ë¦¬', 'ì¶”ì²œ', 'BEST', 'TOP'
        ]
        
        clean_name = raw_name
        for word in junk_words:
            clean_name = clean_name.replace(word, "")
        
        # 2. íŠ¹ìˆ˜ê¸°í˜¸ ì œê±° ë° ë‹¤ë“¬ê¸°
        import re
        clean_name = re.sub(r'[\-\|\:\[\]\(\)]', ' ', clean_name) # ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ
        clean_name = re.sub(r'\s+', ' ', clean_name).strip()     # ì—°ì† ê³µë°± ì œê±°
        
        # 3. ë„ˆë¬´ ê¸¸ë©´ ì•ì˜ 2~3ë‹¨ì–´ë§Œ ì‚¬ìš© (ë³´í†µ ì•ì— ê°€ê²Œ ì´ë¦„ì´ ë‚˜ì˜´)
        parts = clean_name.split()
        if len(parts) > 3:
            return " ".join(parts[:2]) # 'ì„±ìˆ˜ë™ ë² ì´í¬ëª¨êµ´' ì •ë„ë¡œ ì••ì¶•
            
        return clean_name
    
    def _get_google_data(self, name: str, location: str) -> Optional[Dict]:
        """Google Places API ê²€ì¦ (ì´ë¦„ ì •ì œ ë¡œì§ í¬í•¨) - ì§€ì—­ ê²€ì¦ ì¶”ê°€"""
        try:
            # [ìˆ˜ì •] ì§€ì €ë¶„í•œ ì´ë¦„ì„ ì²­ì†Œí•˜ê³  ê²€ìƒ‰
            search_name = self._clean_place_name(name)
            query = f"{location} {search_name}"
            
            #print(f"   ğŸ” êµ¬ê¸€ ê²€ìƒ‰ ì‹œë„: '{query}'") # ì–´ë–¤ í‚¤ì›Œë“œë¡œ êµ¬ê¸€ì— ë¬¼ì–´ë³´ëŠ”ì§€ í™•ì¸ìš©
            
            res = self.gmaps.places(query=query)
            if res.get('results'):
                # ì§€ì—­ ê²€ì¦: ì£¼ì†Œì— í•´ë‹¹ ì§€ì—­ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                location_normalized = self._normalize_location(location)
                
                for place in res.get('results', []):
                    address = place.get("formatted_address", "")
                    
                    # ì£¼ì†Œì— í•´ë‹¹ ì§€ì—­ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    if self._is_location_match(address, location_normalized, location):
                        return {
                            "name": place.get("name"), # êµ¬ê¸€ì´ í™•ì¸í•´ì¤€ ì§„ì§œ ê°€ê²Œ ì´ë¦„
                            "rating": place.get("rating", 0.0),
                            "reviews_count": place.get("user_ratings_total", 0),
                            "address": address
                        }
                
                # í•´ë‹¹ ì§€ì—­ì— ë§ëŠ” ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ê²°ê³¼ë„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (None ë°˜í™˜)
                # ì´ë ‡ê²Œ í•˜ë©´ ì˜ëª»ëœ ì§€ì—­ì˜ ì¥ì†Œê°€ ì œì™¸ë¨
                return None
        except Exception as e:
            print(f"      âš ï¸ êµ¬ê¸€ API ì—ëŸ¬: {e}")
            return None
        return None
    
    def _normalize_location(self, location: str) -> str:
        """ì§€ì—­ëª… ì •ê·œí™” (ì„œìš¸íŠ¹ë³„ì‹œ -> ì„œìš¸, ë¶€ì‚°ê´‘ì—­ì‹œ -> ë¶€ì‚°)"""
        # í•œêµ­ì˜ ì£¼ìš” ë„ì‹œ ì •ê·œí™”
        location_map = {
            "ì„œìš¸íŠ¹ë³„ì‹œ": "ì„œìš¸",
            "ì„œìš¸ì‹œ": "ì„œìš¸",
            "ë¶€ì‚°ê´‘ì—­ì‹œ": "ë¶€ì‚°",
            "ë¶€ì‚°ì‹œ": "ë¶€ì‚°",
            "ëŒ€êµ¬ê´‘ì—­ì‹œ": "ëŒ€êµ¬",
            "ëŒ€êµ¬ì‹œ": "ëŒ€êµ¬",
            "ì¸ì²œê´‘ì—­ì‹œ": "ì¸ì²œ",
            "ì¸ì²œì‹œ": "ì¸ì²œ",
            "ê´‘ì£¼ê´‘ì—­ì‹œ": "ê´‘ì£¼",
            "ê´‘ì£¼ì‹œ": "ê´‘ì£¼",
            "ëŒ€ì „ê´‘ì—­ì‹œ": "ëŒ€ì „",
            "ëŒ€ì „ì‹œ": "ëŒ€ì „",
            "ìš¸ì‚°ê´‘ì—­ì‹œ": "ìš¸ì‚°",
            "ìš¸ì‚°ì‹œ": "ìš¸ì‚°",
            "ê²½ê¸°ë„": "ê²½ê¸°",
            "ê°•ì›ë„": "ê°•ì›",
            "ì¶©ì²­ë¶ë„": "ì¶©ë¶",
            "ì¶©ì²­ë‚¨ë„": "ì¶©ë‚¨",
            "ì „ë¼ë¶ë„": "ì „ë¶",
            "ì „ë¼ë‚¨ë„": "ì „ë‚¨",
            "ê²½ìƒë¶ë„": "ê²½ë¶",
            "ê²½ìƒë‚¨ë„": "ê²½ë‚¨",
        }
        
        normalized = location_map.get(location, location)
        # ë§ˆì§€ë§‰ìœ¼ë¡œ ê³µë°± ì œê±°
        return normalized.strip()
    
    def _is_location_match(self, address: str, normalized_location: str, original_location: str) -> bool:
        """ì£¼ì†Œê°€ í•´ë‹¹ ì§€ì—­ì— ì†í•˜ëŠ”ì§€ í™•ì¸"""
        if not address:
            return False
        
        # ì£¼ì†Œë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        address_lower = address.lower()
        normalized_lower = normalized_location.lower()
        original_lower = original_location.lower()
        
        # í•œêµ­ì˜ ì£¼ìš” ë„ì‹œë³„ ê²€ì¦ (íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ - ì œì™¸ ë„ì‹œ ë¨¼ì € í™•ì¸)
        # ì˜ˆ: "ì„œìš¸"ì¸ë° ì£¼ì†Œì— "ë¶€ì‚°"ì´ë‚˜ "ê²½ì£¼"ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ False
        exclusion_map = {
            "ì„œìš¸": ["ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ê²½ì£¼", "ì œì£¼"],
            "ë¶€ì‚°": ["ì„œìš¸", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ê²½ì£¼", "ì œì£¼"],
            "ê²½ì£¼": ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì œì£¼"],
        }
        
        # ì œì™¸ ë„ì‹œê°€ ì£¼ì†Œì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ False ë°˜í™˜
        if normalized_location in exclusion_map:
            for excluded_city in exclusion_map[normalized_location]:
                if excluded_city.lower() in address_lower:
                    return False
        
        # ì •ê·œí™”ëœ ì§€ì—­ëª… ë˜ëŠ” ì›ë³¸ ì§€ì—­ëª…ì´ ì£¼ì†Œì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if normalized_lower in address_lower or original_lower in address_lower:
            return True
        
        # ì§€ì—­ëª…ì´ ì£¼ì†Œì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ False
        return False
    
    def _calculate_trust_score_v3(self, google_rating: float, google_reviews: int, content: str, category: str, mention_count: int) -> float:
        """
        [V3] ì¸ê¸°ë„(Mention Count)ê°€ ë°˜ì˜ëœ ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜
        """
        # 1. ê¸°ë³¸ ì ìˆ˜ (í‰ì  0.0ì¸ ìµœì‹  ì¥ì†ŒëŠ” 4.0ì ì—ì„œ ì‹œì‘)
        score = google_rating if google_rating > 0 else 4.0
        
        # 2. ë³´ì¡° ì§€í‘œ 1: êµ¬ê¸€ ë¦¬ë·° ìˆ˜ (ê³µì‹ ì¸ê¸°ë„)
        if google_reviews > 500: score += 0.2
        elif google_reviews > 100: score += 0.1
    
        # 3. ë³´ì¡° ì§€í‘œ 2: ì›¹ ì–¸ê¸‰ íšŸìˆ˜ (íŠ¸ë Œë“œ ì¸ê¸°ë„)
        # ì—¬ëŸ¬ ë¸”ë¡œê·¸/ì‚¬ì´íŠ¸ì—ì„œ ê³µí†µìœ¼ë¡œ ë°œê²¬ë ìˆ˜ë¡ ê°€ì‚°ì  ë¶€ì—¬ (ìµœëŒ€ 0.4)
        if mention_count > 1:
            score += (mention_count - 1) * 0.15

        # 4. ë³´ì¡° ì§€í‘œ 3: í‚¤ì›Œë“œ ê°€ì‚°ì 
        trust_keywords = ['ë‚´ëˆë‚´ì‚°', 'ì†”ì§í›„ê¸°', 'ë¶„ìœ„ê¸°', 'ì¹œì ˆ']
        for kw in trust_keywords:
            if kw in content: score += 0.05
            
        # í™œë™/ê´€ê´‘ì§€ ì „ìš© íŠ¸ë Œë“œ í‚¤ì›Œë“œ
        if category in ['í™œë™', 'ì‡¼í•‘', 'ê´€ê´‘ì§€']:
            if any(kw in content for kw in ['ìµœì‹ ', 'íŒì—…', 'ì˜¤í”ˆ', 'í•«í”Œ']):
                score += 0.1

        return round(min(score, 5.0), 2)


    def validate_input(self, input_data: Dict[str, Any]) -> bool:
        """BaseAgentì˜ í•„ìˆ˜ êµ¬í˜„ ì¶”ìƒ ë©”ì„œë“œ"""
        if not isinstance(input_data, dict):
            return False
        return bool(input_data.get("theme") and input_data.get("location"))