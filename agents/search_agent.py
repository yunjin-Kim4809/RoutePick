import json
import asyncio
import os
import random 
from typing import Any, Dict, Optional, List
from openai import AsyncOpenAI
import googlemaps
from .base_agent import BaseAgent
from tools.tavily_search_tool import TavilySearchTool

class SearchAgent(BaseAgent):
    """
    ì‚¬ìš©ìì˜ í…Œë§ˆë¥¼ [í–‰ë™ ë‹¨ìœ„]ë¡œ ë¶„ì„í•˜ì—¬ [ì½”ìŠ¤ êµ¬ì¡°]ë¥¼ ë¨¼ì € ì„¤ê³„í•˜ê³ ,
    ê·¸ ì„¤ê³„ë¥¼ ì±„ìš¸ ìµœì ì˜ ì¥ì†Œë¥¼ ë°œêµ´ ë° ê²€ì¦í•˜ëŠ” ì „ëµê°€ ì—ì´ì „íŠ¸.
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(name="SearchAgent", config=config)
        self.search_tool = TavilySearchTool(config=config)
        
        # 1. configì—ì„œ ë¨¼ì € ì°¾ê³ , ì—†ìœ¼ë©´ os.environì—ì„œ ì§ì ‘ ì°¾ìŒ
        self.openai_api_key = self.config.get("openai_api_key") or os.getenv("OPENAI_API_KEY")
        self.google_maps_api_key = self.config.get("google_maps_api_key") or os.getenv("GOOGLE_MAPS_API_KEY")
        self.llm_model = self.config.get("llm_model", "gpt-4o-mini")
        
        # 2. í‚¤ê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        if not self.google_maps_api_key:
            raise ValueError("GOOGLE_MAPS_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì´ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        self.client = AsyncOpenAI(api_key=self.openai_api_key)
        self.gmaps = googlemaps.Client(key=self.google_maps_api_key)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ëµ ìˆ˜ë¦½ -> í–‰ë™ ë¶„í•´ -> ê²€ìƒ‰ -> êµ¬ê¸€ ê²€ì¦ -> í›„ë³´ í’€ ë°˜í™˜"""
        if not self.validate_input(input_data):
            return {"success": False, "error": "ì…ë ¥ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

        theme = input_data.get("theme")
        location = input_data.get("location")
        
        # 1. ì „ëµ ìˆ˜ë¦½ (í–‰ë™ ë¶„ì„ ë° ì¹´í…Œê³ ë¦¬ ì„¤ê³„)
        print(f"\nğŸ§  [Step 1] í…Œë§ˆ ë¶„ì„ ë° ì½”ìŠ¤ ì„¤ê³„ ì¤‘...")
        
        strategy = await self._generate_strategy(theme, location)
        if not strategy:
            return {"success": False, "error": "LLM ì „ëµ ìˆ˜ë¦½ ì‹¤íŒ¨"}
        

        # 2. Tavily ë©€í‹° ê²€ìƒ‰ (ë³¸ë¬¸ ë°ì´í„° í™•ë³´)
        print(f"ğŸ“¡ [Step 2] Tavilyë¥¼ í†µí•´ ë°©ëŒ€í•œ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘... (60ê°œ í›„ë³´ íƒìƒ‰)")

        tasks = [
            self.search_tool.execute(query=step['search_query'], max_results=20) 
            for step in strategy['course_structure']
        ]
        search_results = await asyncio.gather(*tasks)
        
        
        print(f"ğŸ“ [Step 3-1] LLMì´ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì§„ì§œ ì¥ì†Œëª…ë§Œ ì¶”ì¶œ ì¤‘...")
        # 3. LLM ì—”í‹°í‹° ì¶”ì¶œ ë° URL ë³´ì¡´
        all_raw_data = []
        for res in search_results:
            if res["success"]:
                # ì œëª©, ë³¸ë¬¸, URLì„ í•œ ê°ì²´ë¡œ ë¬¶ì–´ì„œ ì „ë‹¬
                for p in res["places"]:
                    all_raw_data.append({
                        "url": p['source_url'],
                        "text": f"ì œëª©: {p['name']}, ë³¸ë¬¸: {p['description']}"
                    })
                
        # ë°ì´í„° ìˆœì„œë¥¼ ì„ì–´ì„œ íŠ¹ì • ì¹´í…Œê³ ë¦¬ ì ë¦¼ ë°©ì§€
        random.shuffle(all_raw_data) 
        print(f"ğŸ“ [Step 3-2] LLMì´ 60ê°œ ì›ë¬¸ ì „ì²´ë¥¼ ì „ìˆ˜ ì¡°ì‚¬ ì¤‘...")
        
        # [Step 3 ìˆ˜ì •] ì´ë¦„ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ í•¨ê»˜ ì¶”ì¶œ
        # ìˆ˜ì •ëœ ì¶”ì¶œ í•¨ìˆ˜ í˜¸ì¶œ
        refined_data = await self._extract_place_entities_with_source(all_raw_data, location)

        #  LLMì˜ ì„±ì‹¤ë„ ì²´í¬
        print(f"   âœ… LLMì´ 60ê°œ ë°ì´í„°ì—ì„œ ë°œêµ´í•œ ìœ ë‹ˆí¬ ì¥ì†Œ: {len(refined_data)}ê°œ")

        # ì¸ê¸°ë„(ì–¸ê¸‰ íšŸìˆ˜) ê³„ì‚°
        # ì–´ë–¤ ì¥ì†Œê°€ 60ê°œ ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ì—¬ëŸ¬ ë²ˆ ë“±ì¥í–ˆëŠ”ì§€ ì¹´ìš´íŠ¸í•©ë‹ˆë‹¤.
        mention_counts = {}
        for item in refined_data:
            name = item.get('name')
            mention_counts[name] = mention_counts.get(name, 0) + 1

        # 4. Google Maps ê¸°ë°˜ ê²€ì¦
        category_buckets = {} # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¥ì†Œë¥¼ ë‹´ì„ ë°”êµ¬ë‹ˆ
        seen_names = set() # ì¤‘ë³µ ì œê±°ìš©

        for item in refined_data:
            # ì´ì œ nameë¿ë§Œ ì•„ë‹ˆë¼ categoryë„ item ì•ˆì— ë“¤ì–´ìˆìŠµë‹ˆë‹¤.
            place_name = item.get('name')
            place_category = item.get('category', 'ê¸°íƒ€') # ê¸°ë³¸ê°’ ì„¤ì •
            
            clean_name = self._clean_place_name(place_name)
            google_info = self._get_google_data(clean_name, location)
    
            # ì¹´í…Œê³ ë¦¬ì— ë”°ë¥¸ ìœ ì—°í•œ í•„í„°ë§
            is_valid = False
            cat = place_category
            
            if google_info:
                g_rating = google_info['rating']
                # [ê°•ë ¥ ì²˜ë°©] í‰ì ì´ 0.1~3.0 ì‚¬ì´ë¼ë©´ 'ì§„ì§œ ë‚˜ìœ ê³³' í˜¹ì€ 'ë¶€ë™ì‚°'ì„. ê°€ì°¨ì—†ì´ ì»¤íŠ¸!
                if 0.1 <= g_rating < 3.0:
                    print(f"   - [Hard Cut] {google_info['name']}: í‰ì  {g_rating} (í’ˆì§ˆ ë¯¸ë‹¬)")
                    continue

                if cat in ['ì‹ë‹¹', 'ì¹´í˜']:
                    if g_rating >= 4.0: is_valid = True
                else:
                    is_valid = True # í‰ì  0.0(ì‹ ê·œ) ì´ê±°ë‚˜ 3.0 ì´ìƒì¸ í™œë™/ê´€ê´‘ì§€ëŠ” í†µê³¼
            
            elif cat in ['í™œë™', 'ê´€ê´‘ì§€', 'ì‡¼í•‘']:
                # êµ¬ê¸€ì— ì—†ì–´ë„ LLMì´ ì¶”ì¶œí–ˆë‹¤ë©´ 'ìµœì‹  íŒì—…'ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œ í†µê³¼
                is_valid = True
                google_info = {"name": place_name, "rating": 0.0, "reviews_count": 0, "address": "ì£¼ì†Œ ì •ë³´ í™•ì¸ í•„ìš”"}
            
            
            if is_valid:
                g_name = google_info['name']
                if g_name in seen_names: continue

                # all_raw_dataì—ì„œ ì´ ì¥ì†Œì˜ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì•„ì˜µë‹ˆë‹¤.
                # item['source_url']ê³¼ ì¼ì¹˜í•˜ëŠ” ì›ë¬¸ì„ ê²€ìƒ‰
                original_desc = ""
                for raw in all_raw_data:
                    if raw['url'] == item.get('source_url'):
                        original_desc = raw['text']
                        break
 
                # [V3 ì—…ê·¸ë ˆì´ë“œ] ì–¸ê¸‰ íšŸìˆ˜(Mentions)ë¥¼ ì ìˆ˜ ê³„ì‚°ê¸°ì— ì „ë‹¬
                trust_score = self._calculate_trust_score_v3(
                    google_info['rating'], 
                    google_info['reviews_count'], 
                    original_desc, 
                    cat,
                    mention_counts.get(place_name, 1) # ì–¸ê¸‰ íšŸìˆ˜ ì¶”ê°€
                )

                # ğŸ”— URL ì¸ì½”ë”© ì²˜ë¦¬ (ê³µë°±ì„ +ë¡œ ì¹˜í™˜í•˜ì—¬ í´ë¦­ ê°€ëŠ¥í•˜ê²Œ)
                encoded_name = g_name.replace(" ", "+")
                map_url = f"https://www.google.com/maps/search/?api=1&query={encoded_name}+{location.replace(' ', '+')}"

                print(f"   - [Keep] {google_info['name']} (í‰ì : {google_info['rating']})")
                
                place_obj = {
                    "name": g_name,
                    "category": cat,
                    "rating": google_info['rating'],
                    "trust_score": trust_score,
                    "address": google_info['address'],
                    "source_url": item.get('source_url'),
                    "map_url": map_url
                }

                # [í•µì‹¬ ì¶”ê°€] ë°”êµ¬ë‹ˆì— ë‹´ê¸°
                if cat not in category_buckets:
                    category_buckets[cat] = []
                category_buckets[cat].append(place_obj)

                seen_names.add(g_name)


        # ============================================================
        # 5. [ë¼ìš´ë“œ ë¡œë¹ˆ ì„ ë°œ] ë‹¤ì–‘ì„± ë³´ì¥ ë¡œì§
        # ============================================================
        final_pool = []
        TOTAL_LIMIT = 15

        # ê° ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ ì ìˆ˜ ìˆœìœ¼ë¡œ ë¯¸ë¦¬ ì •ë ¬
        for cat in category_buckets:
            category_buckets[cat].sort(key=lambda x: x['trust_score'], reverse=True)

        # 1ì°¨ ëª©í‘œ: ì „ëµ ì¹´í…Œê³ ë¦¬ (Step 2ì—ì„œ ì„¤ê³„í•œ 3ê°œ)
        strategic_cats = [step['category'] for step in strategy['course_structure']]
        # 2ì°¨ ëª©í‘œ: ë‚˜ë¨¸ì§€ ì¹´í…Œê³ ë¦¬
        other_cats = [c for c in category_buckets.keys() if c not in strategic_cats]
        
        # ì „ì²´ ìˆœíšŒ ìˆœì„œ: [ì „ëµ1, ì „ëµ2, ì „ëµ3, ê¸°íƒ€1, ê¸°íƒ€2...]
        ordered_cats = strategic_cats + other_cats

        # â— [í•µì‹¬] í•œ ë°”í€´ ëŒ ë•Œë§ˆë‹¤ 'ë”± í•œ ê°œì”©'ë§Œ ë½‘ìŠµë‹ˆë‹¤.
        while len(final_pool) < TOTAL_LIMIT:
            added_in_this_round = False
            
            for cat in ordered_cats:
                if len(final_pool) >= TOTAL_LIMIT: break
                
                if cat in category_buckets and category_buckets[cat]:
                    final_pool.append(category_buckets[cat].pop(0))
                    added_in_this_round = True
            
            # ëª¨ë“  ë°”êµ¬ë‹ˆê°€ ë¹„ì—ˆìœ¼ë©´ ì¢…ë£Œ
            if not added_in_this_round:
                break

        # ì¤‘ë³µ ì œê±° (ì´ë¦„ ê¸°ì¤€)
        seen = set()
        unique_final_pool = []
        for p in final_pool:
            if p['name'] not in seen:
                unique_final_pool.append(p)
                seen.add(p['name'])
        
        final_pool = unique_final_pool[:TOTAL_LIMIT]
        
        # SearchAgent.execute()ì˜ ë¦¬í„´ê°’ ë‹¤ìŒ ì—ì´ì „íŠ¸ì—ê²Œ ì¤„ 'ìµœì¢… íŒ¨í‚¤ì§€'
        return {
            "success": True,
            "agent_name": self.name,
            "action_analysis": strategy.get('action_analysis'),
            "candidate_pool": final_pool,
            "user_intent": {
                "course_structure": strategy.get('course_structure'),
                # ì—¬ê¸°ì— reasoning ì •ë³´ê°€ stepë³„ë¡œ í¬í•¨ë˜ì–´ ìˆì–´ ë°ì´í„°ê°€ íœ˜ë°œë˜ì§€ ì•ŠìŒ
                "raw_theme": theme,
                "location": location
            }
        }
    

    async def _extract_place_entities_with_source(self, raw_data: List[Dict], location: str) -> List[Dict]:
        """
        [ë²”ìš© ê³ ë„í™”] ì–´ë–¤ í…Œë§ˆì—ì„œë„ 60ê°œ ë°ì´í„°ë¥¼ ìƒ…ìƒ…ì´ ë’¤ì ¸ ìµœëŒ€í•œ ë§ì€ ì¥ì†Œë¥¼ ë°œêµ´í•¨.
        """
        if not raw_data: return []

        prompt = f"""
        ë‹¹ì‹ ì€ ë°©ëŒ€í•œ ì›¹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¹˜ ìˆëŠ” ì¥ì†Œ ì •ë³´ë§Œ ê³¨ë¼ë‚´ëŠ” 'ì—¬í–‰ ì •ë³´ ë§ˆì´ë‹ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤. 
        ì œê³µëœ {len(raw_data)}ê°œì˜ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ {location} ì§€ì—­ì˜ ì§„ì§œ 'ì¥ì†Œëª…'ì„ ì¶”ì¶œí•˜ê³  ë¶„ë¥˜í•˜ì„¸ìš”.

        [ì„ë¬´ 1: ë°ì´í„° ì •ì œ ë° ì¤‘ë³µ ì œê±° (í•„ìˆ˜)]
        - ë™ì¼í•œ ì¥ì†Œê°€ ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì— ë‚˜íƒ€ë‚  ê²½ìš°, ê°€ì¥ ì •ë³´ê°€ ì•Œì°¬ í•˜ë‚˜ì˜ ê²°ê³¼ë¡œ í†µí•©í•˜ì„¸ìš”.
        - ìˆ˜ì‹ì–´ì™€ ì¼ë°˜ ëª…ì‚¬ë¥¼ ì œê±°í•œ 'ìˆœìˆ˜ ìƒí˜¸ëª…'ë§Œ ë‚¨ê¸°ì„¸ìš”. (ì˜ˆ: 'ì„±ìˆ˜ë™ í•«í”Œ ì¹´í˜ ì–´ë‹ˆì–¸' -> 'ì–´ë‹ˆì–¸')
        - í•œ í¬ìŠ¤íŒ…/ê¸°ì‚¬ì— ì—¬ëŸ¬ ì¥ì†Œ(ì˜ˆ: í˜œí™” ë§›ì§‘ 5ê³³ ë¦¬ìŠ¤íŠ¸)ê°€ ìˆë‹¤ë©´ **ë°˜ë“œì‹œ ëª¨ë“  ì¥ì†Œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œ**í•˜ì„¸ìš”.

        [ì„ë¬´ 2: ì—„ê²©í•œ í•„í„°ë§]
        - 'ë§›ì§‘', 'ì½”ìŠ¤', 'ì—¬í–‰ì§€', 'ë°ì´íŠ¸ ì¥ì†Œ'ì™€ ê°™ì€ ì¼ë°˜ ëª…ì¹­ì€ ì¥ì†Œëª…ì—ì„œ ì œì™¸í•˜ì„¸ìš”.
        - êµ¬ê¸€ ì§€ë„ì—ì„œ ê²€ìƒ‰í–ˆì„ ë•Œ ì •í™•íˆ ìœ„ì¹˜ê°€ ë‚˜ì˜¬ ë²•í•œ ê³ ìœ  ëª…ì‚¬ì—¬ì•¼ í•©ë‹ˆë‹¤.
        - 'ê´€ê´‘ê°ì´ ì§ì ‘ ë°©ë¬¸í•˜ì—¬ ì‹œê°„ì„ ë³´ë‚¼ ìˆ˜ ìˆëŠ” ì‹¤ì²´ê°€ ìˆëŠ” ì¥ì†Œ'ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
        - ì œì™¸ ëŒ€ìƒ: ë¶€ë™ì‚°, ì¶”ì§„ìœ„ì›íšŒ, ì•„íŒŒíŠ¸ ë‹¨ì§€ëª…, ë‹¨ìˆœ ì§€ì—­ëª…, ê³µê³µê¸°ê´€, ê¸°ì—… ì‚¬ë¬´ì‹¤.

        [ì„ë¬´ 3: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì§€ì¹¨ (ë²”ìš©)]
        ì•„ë˜ ë¦¬ìŠ¤íŠ¸ ì¤‘ ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”: [ì‹ë‹¹, ì¹´í˜, í™œë™, ì‡¼í•‘, ìˆ™ì†Œ, ê´€ê´‘ì§€, ê¸°íƒ€]
        - ì‹ë‹¹: ë°¥ì§‘, ë ˆìŠ¤í† ë‘, ì£¼ì , ìš”ë¦¬ ì¤‘ì‹¬ ê³µê°„
        - ì¹´í˜: ì»¤í”¼, ë””ì €íŠ¸, ë² ì´ì»¤ë¦¬, ì°»ì§‘
        - í™œë™: ì—°ê·¹, ë®¤ì§€ì»¬, ì†Œê·¹ì¥, ë°©íƒˆì¶œ, ê³µë°©, ì „ì‹œíšŒ, ì›ë°ì´í´ë˜ìŠ¤, íŒì—…ìŠ¤í† ì–´, ìŠ¤í¬ë¦°ìŠ¤í¬ì¸  ë“± 'ì²´í—˜' ì¤‘ì‹¬ ê³µê°„.
        - ê´€ê´‘ì§€: ê³µì›, í•´ìˆ˜ìš•ì¥, ìœ ì ì§€, ëœë“œë§ˆí¬ ë“± 'ê´€ëŒ/í’ê²½' ì¤‘ì‹¬ ê³µê°„.
        - ì‡¼í•‘: í¸ì§‘ìƒµ, ì†Œí’ˆìƒµ, ë°±í™”ì  ë“± ë¬¼ê±´ êµ¬ë§¤ ê³µê°„.
        - ì¶œì²˜: í•´ë‹¹ ì¥ì†Œê°€ ì–¸ê¸‰ëœ ë°ì´í„°ì˜ 'url' í•„ë“œ ê°’ì„ ì •í™•íˆ ë§¤ì¹­í•˜ì„¸ìš”.

        [ì„ë¬´ 4: ì „ìˆ˜ ì¡°ì‚¬ ëª…ë ¹ (ì¤‘ìš”)]
        - ì œê³µëœ 60ê°œì˜ ë°ì´í„°ë¥¼ ì ˆëŒ€ë¡œ ëŒ€ì¶© í›‘ì§€ ë§ˆì„¸ìš”. 
        - ê° ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ëê¹Œì§€ ì½ê³  ìˆ¨ê²¨ì§„ ì¥ì†Œëª…ì„ ëª¨ë‘ ì°¾ì•„ë‚´ì–´ **ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ ê¸¸ê²Œ(30ê°œ ì´ìƒ ëª©í‘œ)** ë§Œë“œì„¸ìš”.
        - ê²°ê³¼ê°€ ë§ì•„ë„ ì¢‹ìœ¼ë‹ˆ ëˆ„ë½ë˜ëŠ” ì¥ì†Œê°€ ì—†ê²Œ í•˜ëŠ” ê²ƒì´ ìµœìš°ì„ ì…ë‹ˆë‹¤.

        [ë¶„ì„í•  ë°ì´í„°]
        {raw_data}

        [ì‘ë‹µ í˜•ì‹ (JSON ê³ ì •)]
        {{
          "results": [
            {{
              "name": "ì¥ì†Œëª…",
              "category": "ì¹´í…Œê³ ë¦¬",
              "source_url": "ë°ì´í„°ì— ì œê³µëœ ì‹¤ì œ url"
            }}
          ]
        }}
        """
        try:
            response = await self.client.chat.completions.create(
                model=self.llm_model,
                messages=[{"role": "system", "content": "You are a professional travel data miner who never skips info. Output only JSON."},
                          {"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            data = json.loads(response.choices[0].message.content)
            return data.get("results", [])
        except Exception as e:
            print(f"âŒ ì—”í‹°í‹° ì¶”ì¶œ ì—ëŸ¬: {e}")
            return []  

    #(ì˜ˆ: ëŒ€í™” ì¤‘ì‹¬, í™œë™ ì¤‘ì‹¬, íœ´ì‹ ì¤‘ì‹¬)
    #(ì˜ˆ: ì¡°ìš©í•œ ì¹´í˜, ì‹¤ë‚´ ì „ì‹œì¥, ë¶„ìœ„ê¸° ìˆëŠ” ì‹ë‹¹)

    async def _generate_strategy(self, theme: str, location: str) -> Optional[Dict]:
        """
        [ìµœì¢… ê³ ë„í™”] ì‹œìŠ¤í…œ í‘œì¤€ ì¹´í…Œê³ ë¦¬ì™€ ì „ëµì„ ì¼ì¹˜ì‹œì¼œ ë°ì´í„° ìœ ì‹¤ì„ ë°©ì§€í•¨.
        """
        # ì‹œìŠ¤í…œì—ì„œ ì •ì˜í•œ 7ê°œ í‘œì¤€ ì¹´í…Œê³ ë¦¬ (Step 3ì˜ ë¶„ë¥˜ì™€ ì¼ì¹˜ì‹œì¼œì•¼ í•¨)
        valid_categories = ["ì‹ë‹¹", "ì¹´í˜", "í™œë™", "ì‡¼í•‘", "ìˆ™ì†Œ", "ê´€ê´‘ì§€", "ê¸°íƒ€"]

        prompt = f"""
        ë‹¹ì‹ ì€ ë² í…Œë‘ ì—¬í–‰ ì„¤ê³„ìì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ í…Œë§ˆë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ 'ì½”ìŠ¤ êµ¬ì¡°'ë¥¼ ì„¤ê³„í•˜ê³ , ê° êµ¬ì¡°ë¥¼ ì±„ìš¸ ê²€ìƒ‰ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

        [ì‚¬ìš©ì ì…ë ¥]
        - í…Œë§ˆ: {theme}
        - ì§€ì—­: {location}

        [ì„ë¬´]
        1. ì´ í…Œë§ˆì— í•„ìš”í•œ 'í–‰ë™ íƒ€ì…(Action Types)'ì„ 3ê°€ì§€ ë¶„ì„í•˜ì„¸ìš”. 
        2. ê° í–‰ë™ì„ ë§Œì¡±í•˜ê¸° ìœ„í•´ ì•„ë˜ [í‘œì¤€ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸] ì¤‘ ê°€ì¥ ì í•©í•œ ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ì”© ë§¤ì¹­í•˜ì„¸ìš”.
           - í‘œì¤€ ì¹´í…Œê³ ë¦¬: {valid_categories}
        
        3. ê° ë‹¨ê³„ë³„ë¡œ Tavily ê²€ìƒ‰ì„ ìœ„í•œ 'ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬'ì™€ ê·¸ ì¿¼ë¦¬ë¥¼ ì„ ì •í•œ 'íŒë‹¨ ê·¼ê±°(reasoning)'ë¥¼ ìƒì„±í•˜ì„¸ìš”.
           (íŒ: 'ì¶”ì²œ', 'ë¦¬ìŠ¤íŠ¸', 'ë¦¬ë·°', 'ë² ìŠ¤íŠ¸' ê°™ì€ ë‹¨ì–´ë¥¼ ì„ì–´ì•¼ êµ¬ì²´ì ì¸ ê°€ê²Œ ì´ë¦„ì´ ì˜ ë‚˜ì˜µë‹ˆë‹¤.)

        [ì‘ë‹µ í˜•ì‹ (JSON ê³ ì •)]
        {{
          "action_analysis": "í–‰ë™ íƒ€ì… ë¶„ì„ ìš”ì•½",
          "course_structure": [
            {{
              "step": 1, 
              "category": "ìœ„ í‘œì¤€ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜", 
              "search_query": "íŒŒì›Œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²€ìƒ‰ì–´", 
              "reasoning": "ì´ ì¿¼ë¦¬ë¥¼ ì„ ì •í•œ ì´ìœ "
            }},
            {{
              "step": 2, 
              "category": "ìœ„ í‘œì¤€ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜", 
              "search_query": "íŒŒì›Œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²€ìƒ‰ì–´", 
              "reasoning": "ì´ ì¿¼ë¦¬ë¥¼ ì„ ì •í•œ ì´ìœ "
            }},
            {{
              "step": 3, 
              "category": "ìœ„ í‘œì¤€ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜", 
              "search_query": "íŒŒì›Œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²€ìƒ‰ì–´", 
              "reasoning": "ì´ ì¿¼ë¦¬ë¥¼ ì„ ì •í•œ ì´ìœ "
            }}
          ]
        }}
        """
        try:
            response = await self.client.chat.completions.create(
                model=self.llm_model,
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)

        except Exception as e:
            print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨(ì¿¼í„° ì´ˆê³¼ ë“±): {e}")
            # Mock ë°ì´í„°ì—ì„œë„ í‘œì¤€ ì¹´í…Œê³ ë¦¬ ëª…ì¹­ì„ ì‚¬ìš©í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
            return {
                "action_analysis": f"{theme}ì„(ë¥¼) ìœ„í•œ ì‹¤ë‚´ì™¸ í˜¼í•© í™œë™ ë° ë™ì„  ìµœì í™” ì „ëµ",
                "course_structure": [
                    {
                        "step": 1, "category": "ì¹´í˜", 
                        "search_query": f"{location} {theme} ë¶„ìœ„ê¸° ì¢‹ì€ ì¹´í˜ ì¶”ì²œ",
                        "reasoning": "í…Œë§ˆì— ë§ëŠ” ì•„ëŠ‘í•œ ë¶„ìœ„ê¸° í˜•ì„±ì„ ìœ„í•´ ì²« ë²ˆì§¸ ì½”ìŠ¤ë¡œ ì„ ì •"
                    },
                    {
                        "step": 2, "category": "í™œë™", 
                        "search_query": f"{location} {theme} ì‹¤ë‚´ ë†€ê±°ë¦¬ ì „ì‹œ ë² ìŠ¤íŠ¸",
                        "reasoning": "ì§€ë£¨í•¨ì„ ë°©ì§€í•˜ê³  í…Œë§ˆì˜ í•µì‹¬ ê²½í—˜ì„ ì œê³µí•˜ê¸° ìœ„í•œ ë©”ì¸ í™œë™ ì„ ì •"
                    },
                    {
                        "step": 3, "category": "ì‹ì‚¬", 
                        "search_query": f"{location} {theme} ë§›ì§‘ ë¦¬ìŠ¤íŠ¸ ë¦¬ë·°",
                        "reasoning": "í™œë™ í›„ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬ë¥¼ ìœ„í•œ í˜„ì§€ ì¸ê¸° ì‹ë‹¹ íƒìƒ‰"
                    }
                ]
            }

    ## í•œë²ˆ ì¶”ê°€í•´ë³´ëŠ” ì²­ì†Œê¸°
    def _clean_place_name(self, raw_name: str) -> str:
        """
        ë¸”ë¡œê·¸ ì œëª© ë“±ì—ì„œ ì‹¤ì œ ê°€ê²Œ ì´ë¦„ë§Œ ë‚¨ê¸°ê¸° ìœ„í•œ ì²­ì†Œê¸°
        ì˜ˆ: 'ì„±ìˆ˜ë™ ì¹´í˜ ë² ì´í¬ëª¨êµ´ ì‹¤ë‚´ ë†€ê±°ë¦¬ - ë„¤ì´ë²„ ë¸”ë¡œê·¸' -> 'ë² ì´í¬ëª¨êµ´'
        """
        # 1. í”í•œ ìˆ˜ì‹ì–´ ë° í”Œë«í¼ ì´ë¦„ ì œê±°
        junk_words = [
            'ë„¤ì´ë²„ ë¸”ë¡œê·¸', 'ë„¤ì´ë²„ í¬ìŠ¤íŠ¸', 'í‹°ìŠ¤í† ë¦¬', 'ì¸ìŠ¤íƒ€ê·¸ë¨', 'Instagram',
            'ìœ íŠœë¸Œ', 'YouTube', 'íŠ¸ë¦½ë‹·ì»´', 'ë‚˜ë¬´ìœ„í‚¤', 'ì´ì •ë¦¬', 'ì¶”ì²œ', 'BEST', 'TOP'
        ]
        
        clean_name = raw_name
        for word in junk_words:
            clean_name = clean_name.replace(word, "")
        
        # 2. íŠ¹ìˆ˜ê¸°í˜¸ ì œê±° ë° ë‹¤ë“¬ê¸°
        import re
        clean_name = re.sub(r'[\-\|\:\[\]\(\)]', ' ', clean_name) # ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ
        clean_name = re.sub(r'\s+', ' ', clean_name).strip()     # ì—°ì† ê³µë°± ì œê±°
        
        # 3. ë„ˆë¬´ ê¸¸ë©´ ì•ì˜ 2~3ë‹¨ì–´ë§Œ ì‚¬ìš© (ë³´í†µ ì•ì— ê°€ê²Œ ì´ë¦„ì´ ë‚˜ì˜´)
        parts = clean_name.split()
        if len(parts) > 3:
            return " ".join(parts[:2]) # 'ì„±ìˆ˜ë™ ë² ì´í¬ëª¨êµ´' ì •ë„ë¡œ ì••ì¶•
            
        return clean_name
    
    def _get_google_data(self, name: str, location: str) -> Optional[Dict]:
        """Google Places API ê²€ì¦ (ì´ë¦„ ì •ì œ ë¡œì§ í¬í•¨)"""
        try:
            # [ìˆ˜ì •] ì§€ì €ë¶„í•œ ì´ë¦„ì„ ì²­ì†Œí•˜ê³  ê²€ìƒ‰
            search_name = self._clean_place_name(name)
            query = f"{location} {search_name}"
            
            print(f"   ğŸ” êµ¬ê¸€ ê²€ìƒ‰ ì‹œë„: '{query}'") # ì–´ë–¤ í‚¤ì›Œë“œë¡œ êµ¬ê¸€ì— ë¬¼ì–´ë³´ëŠ”ì§€ í™•ì¸ìš©
            
            res = self.gmaps.places(query=query)
            if res.get('results'):
                place = res['results'][0]
                return {
                    "name": place.get("name"), # êµ¬ê¸€ì´ í™•ì¸í•´ì¤€ ì§„ì§œ ê°€ê²Œ ì´ë¦„
                    "rating": place.get("rating", 0.0),
                    "reviews_count": place.get("user_ratings_total", 0),
                    "address": place.get("formatted_address")
                }
        except Exception as e:
            print(f"      âš ï¸ êµ¬ê¸€ API ì—ëŸ¬: {e}")
            return None
        return None
    
    def _calculate_trust_score_v3(self, google_rating: float, google_reviews: int, content: str, category: str, mention_count: int) -> float:
        """
        [V3] ì¸ê¸°ë„(Mention Count)ê°€ ë°˜ì˜ëœ ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜
        """
        # 1. ê¸°ë³¸ ì ìˆ˜ (í‰ì  0.0ì¸ ìµœì‹  ì¥ì†ŒëŠ” 4.0ì ì—ì„œ ì‹œì‘)
        score = google_rating if google_rating > 0 else 4.0
        
        # 2. ë³´ì¡° ì§€í‘œ 1: êµ¬ê¸€ ë¦¬ë·° ìˆ˜ (ê³µì‹ ì¸ê¸°ë„)
        if google_reviews > 500: score += 0.2
        elif google_reviews > 100: score += 0.1
    
        # 3. ë³´ì¡° ì§€í‘œ 2: ì›¹ ì–¸ê¸‰ íšŸìˆ˜ (íŠ¸ë Œë“œ ì¸ê¸°ë„)
        # ì—¬ëŸ¬ ë¸”ë¡œê·¸/ì‚¬ì´íŠ¸ì—ì„œ ê³µí†µìœ¼ë¡œ ë°œê²¬ë ìˆ˜ë¡ ê°€ì‚°ì  ë¶€ì—¬ (ìµœëŒ€ 0.4)
        if mention_count > 1:
            score += (mention_count - 1) * 0.15

        # 4. ë³´ì¡° ì§€í‘œ 3: í‚¤ì›Œë“œ ê°€ì‚°ì 
        trust_keywords = ['ë‚´ëˆë‚´ì‚°', 'ì†”ì§í›„ê¸°', 'ë¶„ìœ„ê¸°', 'ì¹œì ˆ']
        for kw in trust_keywords:
            if kw in content: score += 0.05
            
        # í™œë™/ê´€ê´‘ì§€ ì „ìš© íŠ¸ë Œë“œ í‚¤ì›Œë“œ
        if category in ['í™œë™', 'ì‡¼í•‘', 'ê´€ê´‘ì§€']:
            if any(kw in content for kw in ['ìµœì‹ ', 'íŒì—…', 'ì˜¤í”ˆ', 'í•«í”Œ']):
                score += 0.1

        return round(min(score, 5.0), 2)


    def validate_input(self, input_data: Dict[str, Any]) -> bool:
        """BaseAgentì˜ í•„ìˆ˜ êµ¬í˜„ ì¶”ìƒ ë©”ì„œë“œ"""
        if not isinstance(input_data, dict):
            return False
        return bool(input_data.get("theme") and input_data.get("location"))